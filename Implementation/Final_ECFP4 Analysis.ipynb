{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf2cd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import catboost\n",
    "from catboost import CatBoostRegressor \n",
    "import shap\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.metrics import r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models, layers, optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import graphviz\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import plot_model\n",
    "import keras\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b95d446",
   "metadata": {},
   "source": [
    "# Classification Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7538fac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read ECFP4 and store in dataframe\n",
    "Data_04 = pd.read_csv(r\"data_CHEMBL203-ECFP4.csv\") \n",
    "\n",
    "# Classification Task\n",
    "# add additional column for class label: pXC50 > 6 class 1 otherwise class 0\n",
    "Class = Data_04['pXC50'] >= 6\n",
    "Classes = []\n",
    "for i in Class:\n",
    "    if i == True:\n",
    "        Classes.append(1)\n",
    "    elif i == False:\n",
    "        Classes.append(0)\n",
    "\n",
    "Data_04['Class'] = Classes\n",
    "X04 = Data_04.drop(['Smiles','pXC50','Class'],axis=1)\n",
    "Y04 = Data_04['Class'].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1d7b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE to balance Dataset\n",
    "smote = SMOTE(sampling_strategy='minority',random_state=42)\n",
    "X_sm, y_sm = smote.fit_resample(X, Y)\n",
    "\n",
    "# check class count\n",
    "y_s = list(Y_train) + list(Y_val) + list(Y_test)\n",
    "pd.Series(y_s).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dc4089",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data to trainin, validation and testing \n",
    "X_train, X_tes, Y_train, Y_tes = train_test_split(X_sm, y_sm, test_size=0.2,random_state=42)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_tes, Y_tes, test_size=0.5,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae39293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop and train Catboost classification model using training and validation sets\n",
    "\n",
    "params = {'iterations':3000,\n",
    "        'learning_rate':0.01,\n",
    "        'depth':7,\n",
    "        'eval_metric':'Accuracy',\n",
    "        'verbose':200,\n",
    "        'od_type':\"Iter\", # overfit detector\n",
    "        'od_wait':1000, # most recent best iteration to wait before stopping\n",
    "        'random_seed': 2}\n",
    "\n",
    "cat_model = CatBoostClassifier(**params)\n",
    "cat_model.fit(X_train, Y_train,   \n",
    "          eval_set=(X_val, Y_val), \n",
    "          use_best_model=False, # True if we don't want to save trees created after iteration with the best validation score\n",
    "          plot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f9a4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(Y_test,cat_model.predict(X_test))) # Evaluate Catboost model using test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a8036c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.xticks(size=17,weight='bold')\n",
    "plt.yticks(size=17,weight='bold')\n",
    "plt.title('Confusion Matrix for Catboost Algorithm',size=20,weight='bold')\n",
    "sns.heatmap(confusion_matrix(Y_test, cat_model.predict(X_test)),annot=True,fmt='g',annot_kws={\"size\": 20,'weight':'bold'})\n",
    "plt.savefig('Catboost CM 04',dpi=100,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628ef068",
   "metadata": {},
   "source": [
    "# SHAP Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859661bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = cat_model.predict(X_test)\n",
    "X_df = pd.DataFrame(X_test)\n",
    "x_df = X_df.copy(deep=True)\n",
    "x_df_1st = x_df.copy(deep=True)\n",
    "x_df_1st['1st'] = all_preds\n",
    "x_df = x_df.reset_index().drop('index',axis=1)\n",
    "x_df_1st = x_df_1st.reset_index().drop('index',axis=1)\n",
    "shap_values = shap.TreeExplainer(cat_model).shap_values(x_df) # Apply Shap\n",
    "#shap.summary_plot(shap_values, x_df)\n",
    "'Effect of input parameters on Pmax'\n",
    "shap.summary_plot(shap_values, x_df,plot_size=(10,10),show=False,plot_type='dot',max_display=10)\n",
    "plt.title('SHAP for CatBoost',weight='bold',size=20)\n",
    "plt.xticks(size=20,weight='bold')\n",
    "plt.yticks(size=20,weight='bold')\n",
    "plt.savefig('SHAP 04Classify',dpi=100,bbox_inches='tight')\n",
    "\n",
    "shap_values = shap.TreeExplainer(cat_model).shap_values(x_df)\n",
    "feature_imp = np.mean(np.abs(shap_values),axis=0)\n",
    "feature_imp.shape\n",
    "\n",
    "# top 10 important features\n",
    "ind = feature_imp.argsort()[-10:]\n",
    "ind = ind[::-1] #arranging in descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5c499a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(x_df.columns)[ind]\n",
    "feature_imp[ind]\n",
    "plt.figure(figsize=(10,8))\n",
    "plot = sns.barplot(x=np.array(x_df.columns)[ind],y=feature_imp[ind],color=[0.1,0.2,0.1],order=ind)\n",
    "plot.set_xticklabels(plot.get_xticklabels(), horizontalalignment='center',size=12)\n",
    "plt.yticks(size=15,weight='bold')\n",
    "plt.xticks(size=20,rotation=20,weight='bold')\n",
    "plt.ylabel('Shap feature absolute importance',size=15,weight='bold')\n",
    "plt.savefig('SHAP Feature Importance CB 04',dpi=100,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2675e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model architecture with regularization and dropout\n",
    "CNN = Sequential()\n",
    "CNN.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(1024, 1), kernel_regularizer=l2(0.001)))\n",
    "CNN.add(Conv1D(filters=64, kernel_size=3, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "CNN.add(MaxPooling1D(pool_size=2))\n",
    "CNN.add(Flatten())\n",
    "CNN.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "CNN.add(Dropout(0.5))\n",
    "CNN.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model with binary crossentropy loss and Adam optimizer\n",
    "CNN.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Add early stopping callback to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min')\n",
    "with open('CNN_Classification.txt', 'w') as f:\n",
    "    CNN.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "# Print the model summary\n",
    "print(CNN.summary())\n",
    "keras.utils.plot_model(CNN, \"my_first_model.png\",dpi=300)\n",
    "\n",
    "# Fit the model with early stopping and validation data\n",
    "history = CNN.fit(X_train, Y_train, epochs=100, validation_data=(X_val, Y_val), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c151ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "# Plot the training and validation loss\n",
    "plt.plot(history.history['loss'],linewidth=5,linestyle='-')\n",
    "plt.plot(history.history['val_loss'],linewidth=5,linestyle='-')\n",
    "plt.title('CNN Model Loss',size=20,weight='bold')\n",
    "plt.xticks(size=15,weight='bold')\n",
    "plt.yticks(size=15,weight='bold')\n",
    "plt.ylabel('Loss',size=20,weight='bold')\n",
    "plt.xlabel('Epoch',size=20,weight='bold')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right',prop={\"size\":15,'weight':'bold'})\n",
    "plt.savefig('CNN Loss 04',dpi=100,bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "# Plot the training and validation accuracy\n",
    "plt.plot(history.history['accuracy'],linewidth=5,linestyle='-')\n",
    "plt.plot(history.history['val_accuracy'],linewidth=5,linestyle='-')\n",
    "plt.title('CNN Model Accuracy',size=20,weight='bold')\n",
    "plt.xticks(size=15,weight='bold')\n",
    "plt.yticks(size=15,weight='bold')\n",
    "plt.ylabel('Accuracy',size=20,weight='bold')\n",
    "plt.xlabel('Epoch',size=20,weight='bold')\n",
    "plt.legend(['Train', 'Validation'], loc='lower right',prop={\"size\":15,'weight':'bold'})\n",
    "plt.savefig('CNN Accuracy 04,dpi=100,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dff99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation and Visualization\n",
    "preds = CNN.predict(X_test)\n",
    "y_pred_binary = (preds >= 0.5).astype(int)\n",
    "print(metrics.classification_report(Y_test,y_pred_binary))\n",
    "\n",
    "# plot confusion matric for CNN\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.xticks(size=17,weight='bold')\n",
    "plt.yticks(size=17,weight='bold')\n",
    "plt.title('Confusion Matrix for CNN',size=20,weight='bold')\n",
    "sns.heatmap(confusion_matrix(Y_test, y_pred_binary),annot=True,fmt='g',cmap='Blues',annot_kws={\"size\": 20,'weight':'bold'})\n",
    "plt.savefig('CNN CM 04',dpi=100,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66da0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89563cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ANN model architecture with regularization and dropout\n",
    "ANN = Sequential()\n",
    "ANN.add(Dense(128, input_dim=1024, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "ANN.add(Dropout(0.5))\n",
    "ANN.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "ANN.add(Dropout(0.5))\n",
    "ANN.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model with binary crossentropy loss and Adam optimizer\n",
    "ANN.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Add early stopping callback to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min')\n",
    "\n",
    "\n",
    "with open('ANN_Classification.txt', 'w') as f:\n",
    "    ANN.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "\n",
    "# Print the model summary\n",
    "print(ANN.summary())\n",
    "\n",
    "# Fit the model to the training data with early stopping and validation data\n",
    "history2 = ANN.fit(X_train, Y_train, epochs=100, batch_size=32, verbose=1, validation_data=(X_test, Y_test), callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the performance of the model on the test data\n",
    "loss, accuracy = ANN.evaluate(X_test, Y_test, verbose=1)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0412ee74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing Results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "# Plot the training and validation loss\n",
    "plt.plot(history2.history['loss'],linewidth=5,linestyle='-')\n",
    "plt.plot(history2.history['val_loss'],linewidth=5,linestyle='-')\n",
    "plt.title('ANN Model Loss',size=20,weight='bold')\n",
    "plt.xticks(size=15,weight='bold')\n",
    "plt.yticks(size=15,weight='bold')\n",
    "plt.ylabel('Loss',size=20,weight='bold')\n",
    "plt.xlabel('Epoch',size=20,weight='bold')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right',prop={\"size\":15,'weight':'bold'})\n",
    "plt.savefig('ANN Loss 04',dpi=100,bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "# Plot the training and validation accuracy\n",
    "plt.plot(history2.history['accuracy'],linewidth=5,linestyle='-')\n",
    "plt.plot(history2.history['val_accuracy'],linewidth=5,linestyle='-')\n",
    "plt.title('ANN Model Accuracy',size=20,weight='bold')\n",
    "plt.xticks(size=15,weight='bold')\n",
    "plt.yticks(size=15,weight='bold')\n",
    "plt.ylabel('Accuracy',size=20,weight='bold')\n",
    "plt.xlabel('Epoch',size=20,weight='bold')\n",
    "plt.legend(['Train', 'Validation'], loc='lower right',prop={\"size\":15,'weight':'bold'})\n",
    "plt.savefig('ANN Accuracy 04',dpi=100,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b534ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation and Visualization\n",
    "preds = ANN.predict(X_test)\n",
    "y_pred_binary = (preds >= 0.5).astype(int)\n",
    "print(metrics.classification_report(Y_test,y_pred_binary))\n",
    "\n",
    "# Plot confusion matrix for ANN\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.xticks(size=17,weight='bold')\n",
    "plt.yticks(size=17,weight='bold')\n",
    "plt.title('Confusion Matrix for ANN',size=20,weight='bold')\n",
    "sns.heatmap(confusion_matrix(Y_test, y_pred_binary),annot=True,fmt='g',cmap='Blues',annot_kws={\"size\": 20,'weight':'bold'})\n",
    "plt.savefig('ANN CM 04',dpi=100,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa463d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the random forest classifier with 100 trees\n",
    "RF = RandomForestClassifier(n_estimators=1000,max_depth=10)\n",
    "\n",
    "# Fit the model to the training data\n",
    "RF.fit(X_train, Y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = RF.predict(X_test)\n",
    "\n",
    "\n",
    "# Display classification report and plot RF confusion matrix\n",
    "print(metrics.classification_report(Y_test,RF.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ad913e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Visualization\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.xticks(size=17,weight='bold')\n",
    "plt.yticks(size=17,weight='bold')\n",
    "plt.title('Confusion Matrix for Random Forest',size=20,weight='bold')\n",
    "sns.heatmap(confusion_matrix(Y_test, RF.predict(X_test)),annot=True,fmt='g',cmap='Blues',annot_kws={\"size\": 20,'weight':'bold'})\n",
    "plt.savefig('RF CM 04',dpi=100,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017c42e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the SVM model with a linear kernel\n",
    "SVC = svm.SVC(kernel='rbf',class_weight='balanced', probability=True)\n",
    "\n",
    "# Fit the model to the training data\n",
    "SVC.fit(X_train, Y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = SVC.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e394c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display classification report and plot SVM confusion matrix\n",
    "print(metrics.classification_report(Y_test,SVC.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c1aeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.xticks(size=17,weight='bold')\n",
    "plt.yticks(size=17,weight='bold')\n",
    "plt.title('Confusion Matrix for SVC',size=20,weight='bold')\n",
    "sns.heatmap(confusion_matrix(Y_test, SVC.predict(X_test)),annot=True,fmt='g',cmap='Blues',annot_kws={\"size\": 20,'weight':'bold'})\n",
    "plt.savefig('SVC CM 04',dpi=100,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c62099",
   "metadata": {},
   "source": [
    "# Regression Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0274566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression Task\n",
    "X_Pos = Data_Positive.drop(['Smiles','Class','pXC50'],axis=1)\n",
    "Y_Pos = Data_Positive['pXC50'].values.reshape(-1,1)\n",
    "\n",
    "Y_Pos = pd.Series(Y_Pos.reshape(1,-1)[0])\n",
    "\n",
    "new_clm_heads = [x for x in range(0,len(X_Pos.columns))]\n",
    "X_Pos.columns = new_clm_heads\n",
    "\n",
    "Data_Positive = Data_04[Data_04['pXC50']>=6]\n",
    "Data_Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df541f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data with active molecules to training, validation and testing\n",
    "X_train, X_tes, Y_train, Y_tes = train_test_split(X_Pos, df, test_size=0.1, random_state=42,stratify=df.iloc[:,1])\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_tes, Y_tes, test_size=0.5, random_state=42,stratify=Y_tes.iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad53610a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop Catboost model\n",
    "\n",
    "params = {'iterations':5000,\n",
    "        'learning_rate':0.01,\n",
    "        'depth':8,\n",
    "        'eval_metric':'R2',\n",
    "        'verbose':200,\n",
    "        'od_type':\"Iter\", # overfit detector\n",
    "        'od_wait':1000, # most recent best iteration to wait before stopping\n",
    "        'random_seed': 8\n",
    "          }\n",
    "\n",
    "cat_model = CatBoostRegressor(**params)\n",
    "cat_model.fit(X_train, Y_train.iloc[:,0],   \n",
    "          eval_set=(X_val, Y_val.iloc[:,0]), \n",
    "          use_best_model=True, # True if we don't want to save trees created after iteration with the best validation score\n",
    "          plot=True );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f415a033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "pred_train = cat_model.predict(X_train)\n",
    "pred_val = cat_model.predict(X_val)\n",
    "pred_test = cat_model.predict(X_test)\n",
    "\n",
    "print(np.sqrt(np.mean((Y_train.iloc[:,0]-pred_train)**2)))\n",
    "print(np.sqrt(np.mean((Y_val.iloc[:,0]-pred_val)**2)))\n",
    "print(np.sqrt(np.mean((Y_test.iloc[:,0]-pred_test)**2)))\n",
    "print('\\n')\n",
    "print(r2_score(Y_train.iloc[:,0],pred_train))\n",
    "print(r2_score(Y_val.iloc[:,0],pred_val))\n",
    "print(r2_score(Y_test.iloc[:,0],pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a897e7",
   "metadata": {},
   "source": [
    "# SHAP Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45475f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply  SHAP for Catboost\n",
    "all_preds = cat_model.predict(X_test)\n",
    "\n",
    "X_df = pd.DataFrame(X_test)\n",
    "\n",
    "x_df = X_df.copy(deep=True)\n",
    "x_df_1st = x_df.copy(deep=True)\n",
    "\n",
    "x_df_1st['1st'] = all_preds\n",
    "\n",
    "x_df = x_df.reset_index().drop('index',axis=1)\n",
    "x_df_1st = x_df_1st.reset_index().drop('index',axis=1)\n",
    "\n",
    "\n",
    "shap_values = shap.TreeExplainer(cat_model).shap_values(x_df)\n",
    "#shap.summary_plot(shap_values, x_df)\n",
    "\n",
    "\n",
    "'Effect of input parameters on Pmax'\n",
    "shap.summary_plot(shap_values, x_df,plot_size=(10,10),show=False,plot_type='dot',max_display=10)\n",
    "plt.title('SHAP for CatBoost',weight='bold',size=20)\n",
    "plt.xticks(size=20,weight='bold')\n",
    "plt.yticks(size=20,weight='bold')\n",
    "plt.savefig('Reg SHAP 04',dpi=100,bbox_inches='tight')\n",
    "\n",
    "\n",
    "shap_values = shap.TreeExplainer(cat_model).shap_values(x_df)\n",
    "feature_imp = np.mean(np.abs(shap_values),axis=0)\n",
    "feature_imp.shape\n",
    "\n",
    "# top 10 important features\n",
    "ind = feature_imp.argsort()[-10:]\n",
    "ind = ind[::-1] #arranging in descending order\n",
    "\n",
    "np.array(x_df.columns)[ind]\n",
    "feature_imp[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e3bd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(10,8))\n",
    "plot = sns.barplot(x=np.array(x_df.columns)[ind],y=feature_imp[ind],color=[0.1,0.2,0.1])\n",
    "plot.set_xticklabels(plot.get_xticklabels(), horizontalalignment='center',size=12)\n",
    "plt.yticks(size=15,weight='bold')\n",
    "plt.xticks(size=20,rotation=20,weight='bold')\n",
    "plt.ylabel('Shap absolute feature importance',size=15,weight='bold')\n",
    "plt.savefig('Reg SHAP Feature Importance CB 04',dpi=100,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb37051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop ANN model\n",
    "ANN_reg = models.Sequential()\n",
    "ANN_reg.add(layers.Dense(100, input_dim = 1024, activation='relu',kernel_regularizer=l2(0.01)))\n",
    "ANN_reg.add(layers.Dense(200, activation='relu',kernel_regularizer=l2(0.01)))\n",
    "ANN_reg.add(layers.Dense(300, activation='relu',kernel_regularizer=l2(0.01)))\n",
    "ANN_reg.add(layers.Dense(100, activation='relu',kernel_regularizer=l2(0.01)))\n",
    "ANN_reg.add(layers.Dense(10, activation='relu',kernel_regularizer=l2(0.01)))\n",
    "ANN_reg.add(layers.Dense(1))\n",
    "ANN_reg.compile(optimizer='adam',loss='mse',metrics=['mse'])\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=25, verbose=1, mode='min')\n",
    "callbacks=[early_stopping]\n",
    "\n",
    "history2 = ANN_reg.fit(X_train, Y_train.iloc[:,0], epochs=500, batch_size=50,validation_data=(X_val, Y_val.iloc[:,0]))\n",
    "pred_train = ANN_reg.predict(X_train)\n",
    "pred_val = ANN_reg.predict(X_val)\n",
    "pred_test = ANN_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6c0ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop RF model           \n",
    "rf_default = RandomForestRegressor(n_estimators=3000,max_depth=12)\n",
    "rf_default.fit(X_train,Y_train.iloc[:,0])\n",
    "print(rf_default.score(X_train,Y_train.iloc[:,0]))\n",
    "print(rf_default.score(X_val,Y_val.iloc[:,0]))\n",
    "print(rf_default.score(X_test,Y_test.iloc[:,0]))\n",
    "\n",
    "pred_train = rf_default.predict(X_train)\n",
    "pred_test = rf_default.predict(X_test)\n",
    "pred_val = rf_default.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09773d3",
   "metadata": {},
   "source": [
    "# SHAP Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c740b0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplly SHAP for RF            \n",
    "all_preds = rf_default.predict(X_test)\n",
    "\n",
    "X_df = pd.DataFrame(X_test)\n",
    "\n",
    "x_df = X_df.copy(deep=True)\n",
    "x_df_1st = x_df.copy(deep=True)\n",
    "\n",
    "x_df_1st['1st'] = all_preds\n",
    "\n",
    "x_df = x_df.reset_index().drop('index',axis=1)\n",
    "x_df_1st = x_df_1st.reset_index().drop('index',axis=1)\n",
    "\n",
    "\n",
    "shap_values = shap.TreeExplainer(rf_default).shap_values(x_df)\n",
    "#shap.summary_plot(shap_values, x_df)\n",
    "\n",
    "\n",
    "'Effect of input parameters on Pmax'\n",
    "shap.summary_plot(shap_values, x_df,plot_size=(10,10),show=False,plot_type='dot',max_display=10)\n",
    "plt.title('SHAP for Random Forest',weight='bold',size=20)\n",
    "plt.xticks(size=20,weight='bold')\n",
    "plt.yticks(size=20,weight='bold')\n",
    "plt.savefig('RF Reg SHAP 04',dpi=100,bbox_inches='tight')\n",
    "\n",
    "shap_values = shap.TreeExplainer(rf_default).shap_values(x_df)\n",
    "feature_imp = np.mean(np.abs(shap_values),axis=0)\n",
    "feature_imp.shape\n",
    "\n",
    "# top 10 important features\n",
    "ind = feature_imp.argsort()[-10:]\n",
    "ind = ind[::-1] #arranging in descending order\n",
    "\n",
    "np.array(x_df.columns)[ind]\n",
    "feature_imp[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd56d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Results\n",
    "plt.figure(figsize=(10,8))\n",
    "plot = sns.barplot(x=np.array(x_df.columns)[ind],y=feature_imp[ind],color=[0.1,0.2,0.1])\n",
    "plot.set_xticklabels(plot.get_xticklabels(), horizontalalignment='center',size=12)\n",
    "plt.yticks(size=15,weight='bold')\n",
    "plt.xticks(size=20,rotation=20,weight='bold')\n",
    "plt.ylabel('Shap absolute feature importance',size=15,weight='bold')\n",
    "plt.savefig('RF Reg SHAP Feature Importance CB 04',dpi=100,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecf8beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop GBT model\n",
    "            \n",
    "Y_train=Y_train['Values']\n",
    "Ada = GradientBoostingRegressor(random_state=42)\n",
    "Ada.fit(X_train,Y_train)\n",
    "\n",
    "Ada.score(X_test,Y_test)\n",
    "\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'max_depth': [4,6,10],'n_estimators': [30,100,1000,3000],'learning_rate':[0.1,0.01,0.001]}\n",
    "\n",
    "ada = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = ada, param_grid = param_grid, \n",
    "                          cv = 10, n_jobs = -1, verbose = 2,scoring='r2')\n",
    "\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, Y_train)\n",
    "grid_search.best_params_\n",
    "\n",
    "best_grid_GBT = grid_search.best_estimator_\n",
    "\n",
    "best_grid_GBT\n",
    "best_grid_GBT.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e55b4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develope GBT Model\n",
    "Ada = GradientBoostingRegressor(n_estimators=3000,max_depth=12,random_state=42)\n",
    "Ada.fit(X_train,Y_train.iloc[:,0])\n",
    "\n",
    "Ada.score(X_test,Y_test.iloc[:,0])\n",
    "pred_train = Ada.predict(X_train)\n",
    "pred_test = Ada.predict(X_test)\n",
    "pred_val = Ada.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c014cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop SVR model\n",
    "SVR = svm.SVR(kernel='rbf',degree=3,C=3)\n",
    "\n",
    "SVR.fit(X_train,Y_train.iloc[:,0])\n",
    "pred_train = SVR.predict(X_train)\n",
    "pred_test = SVR.predict(X_test)\n",
    "pred_val = SVR.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9879b655",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
