{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38cacca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import catboost\n",
    "from catboost import CatBoostRegressor \n",
    "import shap\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.metrics import r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models, layers, optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import graphviz\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import plot_model\n",
    "import keras\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea96b9f",
   "metadata": {},
   "source": [
    "# Classification Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89771ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read ECFP4 and store in dataframe\n",
    "Data_06 = pd.read_csv(r\"data_CHEMBL203-ECFP6.csv\") \n",
    "\n",
    "\n",
    "# Classification Task\n",
    "# Add additional column for class label: pXC50 > 6 class 1 otherwise class 0\n",
    "Class = Data_06['pXC50'] >= 6\n",
    "Classes = []\n",
    "for i in Class:\n",
    "    if i == True:\n",
    "        Classes.append(1)\n",
    "    elif i == False:\n",
    "        Classes.append(0)\n",
    "\n",
    "Data_06['Class'] = Classes\n",
    "X06 = Data_06.drop(['Smiles','pXC50','Class'],axis=1)\n",
    "Y06 = Data_06['Class'].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba64a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply SMOTE to balance Dataset\n",
    "smote = SMOTE(sampling_strategy='minority',random_state=42)\n",
    "X_sm, y_sm = smote.fit_resample(X, Y)\n",
    "\n",
    "# check class count\n",
    "y_s = list(Y_train) + list(Y_val) + list(Y_test)\n",
    "pd.Series(y_s).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137494ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data to trainin, validation and testing \n",
    "X_train, X_tes, Y_train, Y_tes = train_test_split(X_sm, y_sm, test_size=0.2,random_state=42)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_tes, Y_tes, test_size=0.5,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4504f7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop and train Catboost classification model using training and validation sets\n",
    "params = {'iterations':3000,\n",
    "        'learning_rate':0.01,\n",
    "        'depth':7,\n",
    "        'eval_metric':'Accuracy',\n",
    "        'verbose':200,\n",
    "        'od_type':\"Iter\", # overfit detector\n",
    "        'od_wait':1000, # most recent best iteration to wait before stopping\n",
    "        'random_seed': 2}\n",
    "\n",
    "cat_model = CatBoostClassifier(**params)\n",
    "cat_model.fit(X_train, Y_train,   \n",
    "          eval_set=(X_val, Y_val), \n",
    "          use_best_model=False,\n",
    "          plot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47056f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Catboost model using test set\n",
    "print(metrics.classification_report(Y_test,cat_model.predict(X_test))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f057e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.xticks(size=17,weight='bold')\n",
    "plt.yticks(size=17,weight='bold')\n",
    "plt.title('Confusion Matrix for Catboost Algorithm',size=20,weight='bold')\n",
    "sns.heatmap(confusion_matrix(Y_test, cat_model.predict(X_test)),annot=True,fmt='g',annot_kws={\"size\": 20,'weight':'bold'})\n",
    "plt.savefig('Catboost CM 06',dpi=100,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3344688f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SHAP Analysis\n",
    "all_preds = cat_model.predict(X_test)\n",
    "X_df = pd.DataFrame(X_test)\n",
    "x_df = X_df.copy(deep=True)\n",
    "x_df_1st = x_df.copy(deep=True)\n",
    "x_df_1st['1st'] = all_preds\n",
    "x_df = x_df.reset_index().drop('index',axis=1)\n",
    "x_df_1st = x_df_1st.reset_index().drop('index',axis=1)\n",
    "shap_values = shap.TreeExplainer(cat_model).shap_values(x_df) # Apply Shap\n",
    "#shap.summary_plot(shap_values, x_df)\n",
    "\n",
    "shap.summary_plot(shap_values, x_df,plot_size=(10,10),show=False,plot_type='dot',max_display=10)\n",
    "plt.title('SHAP for CatBoost',weight='bold',size=20)\n",
    "plt.xticks(size=20,weight='bold')\n",
    "plt.yticks(size=20,weight='bold')\n",
    "plt.savefig('SHAP 06 Classify',dpi=100,bbox_inches='tight')\n",
    "\n",
    "shap_values = shap.TreeExplainer(cat_model).shap_values(x_df)\n",
    "feature_imp = np.mean(np.abs(shap_values),axis=0)\n",
    "feature_imp.shape\n",
    "\n",
    "# Top 10 important features\n",
    "ind = feature_imp.argsort()[-10:]\n",
    "ind = ind[::-1] #arranging in descending order\n",
    "\n",
    "np.array(x_df.columns)[ind]\n",
    "feature_imp[ind]\n",
    "plt.figure(figsize=(10,8))\n",
    "plot = sns.barplot(x=np.array(x_df.columns)[ind],y=feature_imp[ind],color=[0.1,0.2,0.1],order=ind)\n",
    "plot.set_xticklabels(plot.get_xticklabels(), horizontalalignment='center',size=12)\n",
    "plt.yticks(size=15,weight='bold')\n",
    "plt.xticks(size=20,rotation=20,weight='bold')\n",
    "plt.ylabel('Shap feature absolute importance',size=15,weight='bold')\n",
    "plt.savefig('SHAP Feature Importance CB 06',dpi=100,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7928aca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model architecture with regularization and dropout\n",
    "CNN = Sequential()\n",
    "CNN.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(1024, 1), kernel_regularizer=l2(0.001)))\n",
    "CNN.add(Conv1D(filters=64, kernel_size=3, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "CNN.add(MaxPooling1D(pool_size=2))\n",
    "CNN.add(Flatten())\n",
    "CNN.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "CNN.add(Dropout(0.5))\n",
    "CNN.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model with binary crossentropy loss and Adam optimizer\n",
    "CNN.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Add early stopping callback to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min')\n",
    "with open('CNN_Classification.txt', 'w') as f:\n",
    "    CNN.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "# Print the model summary\n",
    "print(CNN.summary())\n",
    "keras.utils.plot_model(CNN, \"my_first_model.png\",dpi=300)\n",
    "\n",
    "# Fit the model with early stopping and validation data\n",
    "history = CNN.fit(X_train, Y_train, epochs=100, validation_data=(X_val, Y_val), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c5a784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "# Plot the training and validation loss\n",
    "plt.plot(history.history['loss'],linewidth=5,linestyle='-')\n",
    "plt.plot(history.history['val_loss'],linewidth=5,linestyle='-')\n",
    "plt.title('CNN Model Loss',size=20,weight='bold')\n",
    "plt.xticks(size=15,weight='bold')\n",
    "plt.yticks(size=15,weight='bold')\n",
    "plt.ylabel('Loss',size=20,weight='bold')\n",
    "plt.xlabel('Epoch',size=20,weight='bold')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right',prop={\"size\":15,'weight':'bold'})\n",
    "plt.savefig('CNN Loss 06',dpi=100,bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "# Plot the training and validation accuracy\n",
    "plt.plot(history.history['accuracy'],linewidth=5,linestyle='-')\n",
    "plt.plot(history.history['val_accuracy'],linewidth=5,linestyle='-')\n",
    "plt.title('CNN Model Accuracy',size=20,weight='bold')\n",
    "plt.xticks(size=15,weight='bold')\n",
    "plt.yticks(size=15,weight='bold')\n",
    "plt.ylabel('Accuracy',size=20,weight='bold')\n",
    "plt.xlabel('Epoch',size=20,weight='bold')\n",
    "plt.legend(['Train', 'Validation'], loc='lower right',prop={\"size\":15,'weight':'bold'})\n",
    "plt.savefig('CNN Accuracy 06,dpi=100,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a412c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Model Evaluation\n",
    "preds = CNN.predict(X_test)\n",
    "y_pred_binary = (preds >= 0.5).astype(int)\n",
    "print(metrics.classification_report(Y_test,y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae780710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matric for CNN\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.xticks(size=17,weight='bold')\n",
    "plt.yticks(size=17,weight='bold')\n",
    "plt.title('Confusion Matrix for CNN',size=20,weight='bold')\n",
    "sns.heatmap(confusion_matrix(Y_test, y_pred_binary),annot=True,fmt='g',cmap='Blues',annot_kws={\"size\": 20,'weight':'bold'})\n",
    "plt.savefig('CNN CM 06',dpi=100,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbb8b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a82d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ANN model architecture with regularization and dropout\n",
    "ANN = Sequential()\n",
    "ANN.add(Dense(128, input_dim=1024, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "ANN.add(Dropout(0.5))\n",
    "ANN.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "ANN.add(Dropout(0.5))\n",
    "ANN.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model with binary crossentropy loss and Adam optimizer\n",
    "ANN.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Add early stopping callback to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min')\n",
    "\n",
    "\n",
    "with open('ANN_Classification.txt', 'w') as f:\n",
    "    ANN.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "\n",
    "# Print the model summary\n",
    "print(ANN.summary())\n",
    "\n",
    "# Fit the model to the training data with early stopping and validation data\n",
    "history2 = ANN.fit(X_train, Y_train, epochs=100, batch_size=32, verbose=1, validation_data=(X_test, Y_test), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e082375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the performance of the model on the test data\n",
    "loss, accuracy = ANN.evaluate(X_test, Y_test, verbose=1)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3af4a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "# Plot the training and validation loss\n",
    "plt.plot(history2.history['loss'],linewidth=5,linestyle='-')\n",
    "plt.plot(history2.history['val_loss'],linewidth=5,linestyle='-')\n",
    "plt.title('ANN Model Loss',size=20,weight='bold')\n",
    "plt.xticks(size=15,weight='bold')\n",
    "plt.yticks(size=15,weight='bold')\n",
    "plt.ylabel('Loss',size=20,weight='bold')\n",
    "plt.xlabel('Epoch',size=20,weight='bold')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right',prop={\"size\":15,'weight':'bold'})\n",
    "plt.savefig('ANN Loss 06',dpi=100,bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "# Plot the training and validation accuracy\n",
    "plt.plot(history2.history['accuracy'],linewidth=5,linestyle='-')\n",
    "plt.plot(history2.history['val_accuracy'],linewidth=5,linestyle='-')\n",
    "plt.title('ANN Model Accuracy',size=20,weight='bold')\n",
    "plt.xticks(size=15,weight='bold')\n",
    "plt.yticks(size=15,weight='bold')\n",
    "plt.ylabel('Accuracy',size=20,weight='bold')\n",
    "plt.xlabel('Epoch',size=20,weight='bold')\n",
    "plt.legend(['Train', 'Validation'], loc='lower right',prop={\"size\":15,'weight':'bold'})\n",
    "plt.savefig('ANN Accuracy 06',dpi=100,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772289a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN Model Evaluation\n",
    "preds = ANN.predict(X_test)\n",
    "y_pred_binary = (preds >= 0.5).astype(int)\n",
    "print(metrics.classification_report(Y_test,y_pred_binary))\n",
    "\n",
    "# Plot confusion matrix for ANN\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.xticks(size=17,weight='bold')\n",
    "plt.yticks(size=17,weight='bold')\n",
    "plt.title('Confusion Matrix for ANN',size=20,weight='bold')\n",
    "sns.heatmap(confusion_matrix(Y_test, y_pred_binary),annot=True,fmt='g',cmap='Blues',annot_kws={\"size\": 20,'weight':'bold'})\n",
    "plt.savefig('ANN CM 06',dpi=100,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19a5fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the random forest classifier with 100 trees\n",
    "RF = RandomForestClassifier(n_estimators=1000,max_depth=10)\n",
    "\n",
    "# Fit the model to the training data\n",
    "RF.fit(X_train, Y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = RF.predict(X_test)\n",
    "\n",
    "\n",
    "# Display classification report and plot RF confusion matrix\n",
    "print(metrics.classification_report(Y_test,RF.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2f7191",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.xticks(size=17,weight='bold')\n",
    "plt.yticks(size=17,weight='bold')\n",
    "plt.title('Confusion Matrix for Random Forest',size=20,weight='bold')\n",
    "sns.heatmap(confusion_matrix(Y_test, RF.predict(X_test)),annot=True,fmt='g',cmap='Blues',annot_kws={\"size\": 20,'weight':'bold'})\n",
    "plt.savefig('RF CM 06',dpi=100,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dced20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your training data and labels into X and y, and your test data into X_test\n",
    "# Define the SVM model with a linear kernel\n",
    "SVC = svm.SVC(kernel='rbf',class_weight='balanced', probability=True)\n",
    "\n",
    "# Fit the model to the training data\n",
    "SVC.fit(X_train, Y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = SVC.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ece0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display classification report and plot SVM confusion matrix\n",
    "print(metrics.classification_report(Y_test,SVC.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb136c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.xticks(size=17,weight='bold')\n",
    "plt.yticks(size=17,weight='bold')\n",
    "plt.title('Confusion Matrix for SVC',size=20,weight='bold')\n",
    "sns.heatmap(confusion_matrix(Y_test, SVC.predict(X_test)),annot=True,fmt='g',cmap='Blues',annot_kws={\"size\": 20,'weight':'bold'})\n",
    "plt.savefig('SVC CM 06',dpi=100,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e5177d",
   "metadata": {},
   "source": [
    "# Regression Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d960131a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression Task\n",
    "X_Pos = Data_Positive.drop(['Smiles','Class','pXC50'],axis=1)\n",
    "Y_Pos = Data_Positive['pXC50'].values.reshape(-1,1)\n",
    "\n",
    "Y_Pos = pd.Series(Y_Pos.reshape(1,-1)[0])\n",
    "\n",
    "new_clm_heads = [x for x in range(0,len(X_Pos.columns))]\n",
    "X_Pos.columns = new_clm_heads\n",
    "\n",
    "Data_Positive = Data_06[Data_06['pXC50']>=6]\n",
    "Data_Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215c49f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data with active molecules to training, validation and testing\n",
    "X_train, X_tes, Y_train, Y_tes = train_test_split(X_Pos, df, test_size=0.1, random_state=42,stratify=df.iloc[:,1])\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_tes, Y_tes, test_size=0.5, random_state=42,stratify=Y_tes.iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a32b3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop Catboost model\n",
    "\n",
    "params = {'iterations':5000,\n",
    "        'learning_rate':0.01,\n",
    "        'depth':8,\n",
    "        'eval_metric':'R2',\n",
    "        'verbose':200,\n",
    "        'od_type':\"Iter\", # overfit detector\n",
    "        'od_wait':1000, # most recent best iteration to wait before stopping\n",
    "        'random_seed': 8\n",
    "          }\n",
    "\n",
    "cat_model = CatBoostRegressor(**params)\n",
    "cat_model.fit(X_train, Y_train.iloc[:,0],   \n",
    "          eval_set=(X_val, Y_val.iloc[:,0]), \n",
    "          use_best_model=True, # True if we don't want to save trees created after iteration with the best validation score\n",
    "          plot=True );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cd036e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "pred_train = cat_model.predict(X_train)\n",
    "pred_val = cat_model.predict(X_val)\n",
    "pred_test = cat_model.predict(X_test)\n",
    "\n",
    "print(np.sqrt(np.mean((Y_train.iloc[:,0]-pred_train)**2)))\n",
    "print(np.sqrt(np.mean((Y_val.iloc[:,0]-pred_val)**2)))\n",
    "print(np.sqrt(np.mean((Y_test.iloc[:,0]-pred_test)**2)))\n",
    "print('\\n')\n",
    "print(r2_score(Y_train.iloc[:,0],pred_train))\n",
    "print(r2_score(Y_val.iloc[:,0],pred_val))\n",
    "print(r2_score(Y_test.iloc[:,0],pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ac2088",
   "metadata": {},
   "source": [
    "# SHAP Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc40cb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply SHAP for Catboost\n",
    "all_preds = cat_model.predict(X_test)\n",
    "\n",
    "X_df = pd.DataFrame(X_test)\n",
    "\n",
    "x_df = X_df.copy(deep=True)\n",
    "x_df_1st = x_df.copy(deep=True)\n",
    "\n",
    "x_df_1st['1st'] = all_preds\n",
    "\n",
    "x_df = x_df.reset_index().drop('index',axis=1)\n",
    "x_df_1st = x_df_1st.reset_index().drop('index',axis=1)\n",
    "\n",
    "\n",
    "shap_values = shap.TreeExplainer(cat_model).shap_values(x_df)\n",
    "#shap.summary_plot(shap_values, x_df)\n",
    "\n",
    "\n",
    "'Effect of input parameters on Pmax'\n",
    "shap.summary_plot(shap_values, x_df,plot_size=(10,10),show=False,plot_type='dot',max_display=10)\n",
    "plt.title('SHAP for CatBoost',weight='bold',size=20)\n",
    "plt.xticks(size=20,weight='bold')\n",
    "plt.yticks(size=20,weight='bold')\n",
    "plt.savefig('Reg SHAP 06',dpi=100,bbox_inches='tight')\n",
    "\n",
    "\n",
    "shap_values = shap.TreeExplainer(cat_model).shap_values(x_df)\n",
    "feature_imp = np.mean(np.abs(shap_values),axis=0)\n",
    "feature_imp.shape\n",
    "\n",
    "# top 10 important features\n",
    "ind = feature_imp.argsort()[-10:]\n",
    "ind = ind[::-1]\n",
    "\n",
    "np.array(x_df.columns)[ind]\n",
    "feature_imp[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899a38e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(10,8))\n",
    "plot = sns.barplot(x=np.array(x_df.columns)[ind],y=feature_imp[ind],color=[0.1,0.2,0.1])\n",
    "plot.set_xticklabels(plot.get_xticklabels(), horizontalalignment='center',size=12)\n",
    "plt.yticks(size=15,weight='bold')\n",
    "plt.xticks(size=20,rotation=20,weight='bold')\n",
    "plt.ylabel('Shap absolute feature importance',size=15,weight='bold')\n",
    "plt.savefig('Reg SHAP Feature Importance CB 06',dpi=100,bbox_inches='tight')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bc0f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop Sequential ANN model\n",
    "ANN_reg = models.Sequential()\n",
    "ANN_reg.add(layers.Dense(100, input_dim = 1024, activation='relu',kernel_regularizer=l2(0.01)))\n",
    "ANN_reg.add(layers.Dense(200, activation='relu',kernel_regularizer=l2(0.01)))\n",
    "ANN_reg.add(layers.Dense(300, activation='relu',kernel_regularizer=l2(0.01)))\n",
    "ANN_reg.add(layers.Dense(100, activation='relu',kernel_regularizer=l2(0.01)))\n",
    "ANN_reg.add(layers.Dense(10, activation='relu',kernel_regularizer=l2(0.01)))\n",
    "ANN_reg.add(layers.Dense(1))\n",
    "ANN_reg.compile(optimizer='adam',loss='mse',metrics=['mse'])\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=25, verbose=1, mode='min')\n",
    "callbacks=[early_stopping]\n",
    "\n",
    "history2 = ANN_reg.fit(X_train, Y_train.iloc[:,0], epochs=500, batch_size=50,validation_data=(X_val, Y_val.iloc[:,0]))\n",
    "pred_train = ANN_reg.predict(X_train)\n",
    "pred_val = ANN_reg.predict(X_val)\n",
    "pred_test = ANN_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c2566b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop RF model       \n",
    "rf_default = RandomForestRegressor(n_estimators=3000,max_depth=12)\n",
    "rf_default.fit(X_train,Y_train.iloc[:,0])\n",
    "print(rf_default.score(X_train,Y_train.iloc[:,0]))\n",
    "print(rf_default.score(X_val,Y_val.iloc[:,0]))\n",
    "print(rf_default.score(X_test,Y_test.iloc[:,0]))\n",
    "\n",
    "pred_train = rf_default.predict(X_train)\n",
    "pred_test = rf_default.predict(X_test)\n",
    "pred_val = rf_default.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21993e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplly SHAP for RF         \n",
    "all_preds = rf_default.predict(X_test)\n",
    "\n",
    "X_df = pd.DataFrame(X_test)\n",
    "\n",
    "x_df = X_df.copy(deep=True)\n",
    "x_df_1st = x_df.copy(deep=True)\n",
    "\n",
    "x_df_1st['1st'] = all_preds\n",
    "\n",
    "x_df = x_df.reset_index().drop('index',axis=1)\n",
    "x_df_1st = x_df_1st.reset_index().drop('index',axis=1)\n",
    "\n",
    "\n",
    "shap_values = shap.TreeExplainer(rf_default).shap_values(x_df)\n",
    "#shap.summary_plot(shap_values, x_df)\n",
    "\n",
    "\n",
    "'Effect of input parameters on Pmax'\n",
    "shap.summary_plot(shap_values, x_df,plot_size=(10,10),show=False,plot_type='dot',max_display=10)\n",
    "plt.title('SHAP for Random Forest',weight='bold',size=20)\n",
    "plt.xticks(size=20,weight='bold')\n",
    "plt.yticks(size=20,weight='bold')\n",
    "plt.savefig('RF Reg SHAP 06',dpi=100,bbox_inches='tight')\n",
    "\n",
    "shap_values = shap.TreeExplainer(rf_default).shap_values(x_df)\n",
    "feature_imp = np.mean(np.abs(shap_values),axis=0)\n",
    "feature_imp.shape\n",
    "\n",
    "# top 10 important features\n",
    "ind = feature_imp.argsort()[-10:]\n",
    "ind = ind[::-1] #arranging in descending order\n",
    "\n",
    "np.array(x_df.columns)[ind]\n",
    "feature_imp[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f4a674",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plot = sns.barplot(x=np.array(x_df.columns)[ind],y=feature_imp[ind],color=[0.1,0.2,0.1])\n",
    "plot.set_xticklabels(plot.get_xticklabels(), horizontalalignment='center',size=12)\n",
    "plt.yticks(size=15,weight='bold')\n",
    "plt.xticks(size=20,rotation=20,weight='bold')\n",
    "plt.ylabel('Shap absolute feature importance',size=15,weight='bold')\n",
    "plt.savefig('RF Reg SHAP Feature Importance CB 06',dpi=100,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd9d676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop GBT model      \n",
    "Y_train=Y_train['Values']\n",
    "Ada = GradientBoostingRegressor(random_state=42)\n",
    "Ada.fit(X_train,Y_train)\n",
    "\n",
    "Ada.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c2f0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'max_depth': [4,6,10],'n_estimators': [30,100,1000,3000],'learning_rate':[0.1,0.01,0.001]}\n",
    "\n",
    "ada = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = ada, param_grid = param_grid,cv = 10, n_jobs = -1, verbose = 2,scoring='r2')\n",
    "\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, Y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0f6c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grid_GBT = grid_search.best_estimator_\n",
    "\n",
    "best_grid_GBT\n",
    "best_grid_GBT.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bd52ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ada = GradientBoostingRegressor(n_estimators=3000,max_depth=12,random_state=42)\n",
    "Ada.fit(X_train,Y_train.iloc[:,0])\n",
    "\n",
    "Ada.score(X_test,Y_test.iloc[:,0])\n",
    "pred_train = Ada.predict(X_train)\n",
    "pred_test = Ada.predict(X_test)\n",
    "pred_val = Ada.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420b5b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop SVR model\n",
    "SVR = svm.SVR(kernel='rbf',degree=3,C=3)\n",
    "\n",
    "SVR.fit(X_train,Y_train.iloc[:,0])\n",
    "pred_train = SVR.predict(X_train)\n",
    "pred_test = SVR.predict(X_test)\n",
    "pred_val = SVR.predict(X_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
